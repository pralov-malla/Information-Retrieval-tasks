{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e28e40b4",
   "metadata": {},
   "source": [
    "### Text Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "538d0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = [\n",
    "    \"I love programming in Python\",\n",
    "    \"Python and Java are popular programming languages\",\n",
    "    \"I enjoy watching movies and series\",\n",
    "    \"Cinema and film industry is booming\",\n",
    "    \"Machine learning and AI are future tech\",\n",
    "    \"Music concerts are fun\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a36ca72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "docs_tokens = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Building vocabulary\n",
    "vocab = sorted(list(set([w for doc in docs_tokens for w in doc])))\n",
    "\n",
    "# Vectorizing documents\n",
    "def vectorize(doc, vocab):\n",
    "    vec = np.zeros(len(vocab))\n",
    "    count = Counter(doc)\n",
    "    for i, word in enumerate(vocab):\n",
    "        vec[i] = count[word]\n",
    "    return vec\n",
    "\n",
    "doc_vectors = np.array([vectorize(doc, vocab) for doc in docs_tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f7c8f2",
   "metadata": {},
   "source": [
    "#### K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4bc4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Clusters: [[0, 1, 3, 4, 5], [2]]\n"
     ]
    }
   ],
   "source": [
    "def kmeans(X, k=2, max_iters=100):\n",
    "    n_samples, n_features = X.shape\n",
    "    # Initializing centroids randomly\n",
    "    np.random.seed(0)\n",
    "    centroids = X[np.random.choice(n_samples, k, replace=False)]\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        clusters = [[] for _ in range(k)]\n",
    "        # Assigning clusters\n",
    "        for idx, x in enumerate(X):\n",
    "            distances = [np.linalg.norm(x - c) for c in centroids]\n",
    "            cluster_idx = np.argmin(distances)\n",
    "            clusters[cluster_idx].append(idx)\n",
    "        # Updating centroids\n",
    "        new_centroids = np.zeros_like(centroids)\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            if cluster:\n",
    "                new_centroids[i] = np.mean(X[cluster], axis=0)\n",
    "            else:\n",
    "                new_centroids[i] = centroids[i]  # if empty cluster\n",
    "        # Checking convergence\n",
    "        if np.allclose(centroids, new_centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    return clusters, centroids\n",
    "\n",
    "clusters_kmeans, centroids_kmeans = kmeans(doc_vectors, k=2)\n",
    "print(\"K-Means Clusters:\", clusters_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32b6f3e",
   "metadata": {},
   "source": [
    "#### K- Mediods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0d3dc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Medoids Clusters: [[0, 1, 3, 4, 5], [2]]\n"
     ]
    }
   ],
   "source": [
    "def kmedoids(X, k=2, max_iters=100):\n",
    "    n_samples = X.shape[0]\n",
    "    np.random.seed(0)\n",
    "    medoid_idx = np.random.choice(n_samples, k, replace=False)\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        clusters = [[] for _ in range(k)]\n",
    "        # Assign clusters based on distance to medoid\n",
    "        for idx, x in enumerate(X):\n",
    "            distances = [np.linalg.norm(x - X[m]) for m in medoid_idx]\n",
    "            cluster_idx = np.argmin(distances)\n",
    "            clusters[cluster_idx].append(idx)\n",
    "        # Update medoids\n",
    "        new_medoids = medoid_idx.copy()\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            if cluster:\n",
    "                intra_distances = [sum(np.linalg.norm(X[p]-X[q]) for q in cluster) for p in cluster]\n",
    "                new_medoids[i] = cluster[np.argmin(intra_distances)]\n",
    "        if np.array_equal(new_medoids, medoid_idx):\n",
    "            break\n",
    "        medoid_idx = new_medoids\n",
    "    return clusters, medoid_idx\n",
    "\n",
    "clusters_kmedoid, medoids = kmedoids(doc_vectors, k=2)\n",
    "print(\"K-Medoids Clusters:\", clusters_kmedoid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00300618",
   "metadata": {},
   "source": [
    "#### Text Shingling( Jaccard's Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8b4333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity Matrix (2-shingles):\n",
      " [[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "def k_shingles(doc, k=2):\n",
    "    tokens = doc\n",
    "    shingles = set()\n",
    "    for i in range(len(tokens)-k+1):\n",
    "        shingles.add(tuple(tokens[i:i+k]))\n",
    "    return shingles\n",
    "\n",
    "shingle_sets = [k_shingles(doc, k=2) for doc in docs_tokens]\n",
    "\n",
    "def jaccard_sim(set1, set2):\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "# Example: compute similarity matrix\n",
    "n = len(shingle_sets)\n",
    "sim_matrix = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        sim_matrix[i,j] = jaccard_sim(shingle_sets[i], shingle_sets[j])\n",
    "\n",
    "print(\"Jaccard Similarity Matrix (2-shingles):\\n\", np.round(sim_matrix, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
