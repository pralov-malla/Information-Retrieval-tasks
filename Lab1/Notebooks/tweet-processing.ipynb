{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe57eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56746e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/test_tweets_anuFYb8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "631e6485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17197 entries, 0 to 17196\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      17197 non-null  int64 \n",
      " 1   tweet   17197 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 268.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8752f983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12453</th>\n",
       "      <td>44416</td>\n",
       "      <td>second day last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>37237</td>\n",
       "      <td>are you locked brother? @user woah spooky got ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>33004</td>\n",
       "      <td>they still aren't seeing my messages...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12266</th>\n",
       "      <td>44229</td>\n",
       "      <td>not ashamed to admit there were tears #happy  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5783</th>\n",
       "      <td>37746</td>\n",
       "      <td>â #us: retail sales steady in may â nomur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet\n",
       "12453  44416                                  second day last  \n",
       "5274   37237  are you locked brother? @user woah spooky got ...\n",
       "1041   33004         they still aren't seeing my messages...   \n",
       "12266  44229  not ashamed to admit there were tears #happy  ...\n",
       "5783   37746   â #us: retail sales steady in may â nomur..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e476eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = df[['tweet']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf879d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  #studiolife #aislife #requires #passion #dedic...\n",
       "1   @user #white #supremacists want everyone to s...\n",
       "2  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  is the hp and the cursed child book up for res...\n",
       "4    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6ceb714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)         # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)            # Remove @mentions\n",
    "    text = re.sub(r'#', '', text)               # Remove hashtag symbol\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)         # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()    # Normalize whitespace\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "441f4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tweet'] = tweets_df['tweet'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8548789e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feeling like a mermaid ð hairflip neverready formal wedding gown dresses mermaid â'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['tweet'][17193]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7191d",
   "metadata": {},
   "source": [
    "### Normalize Unicode (fix weird characters like ð, â)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e3e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_unicode(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e13f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tweet'] = tweets_df['tweet'].apply(normalize_unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e3a625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>we salute the brave police officers who suffer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8302</th>\n",
       "      <td>always be platyctenea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>looking forward to helping a new client get or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>beautifulsunday a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16668</th>\n",
       "      <td>these comments from the failed republican cand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>buttrump amp his followers will swear it was h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>sex blonde best way of having sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12129</th>\n",
       "      <td>no greater test of a psychologists abilities t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>there wasnt so much violence at the last euro ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>cloudchaser bull hill climb you have to reach ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet\n",
       "4870   we salute the brave police officers who suffer...\n",
       "8302                               always be platyctenea\n",
       "7915   looking forward to helping a new client get or...\n",
       "1023                                   beautifulsunday a\n",
       "16668  these comments from the failed republican cand...\n",
       "6493   buttrump amp his followers will swear it was h...\n",
       "3243                   sex blonde best way of having sex\n",
       "12129  no greater test of a psychologists abilities t...\n",
       "193    there wasnt so much violence at the last euro ...\n",
       "3167   cloudchaser bull hill climb you have to reach ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31085a41",
   "metadata": {},
   "source": [
    "### Correcting space problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "417e6b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordninja in c:\\users\\pralo\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wordninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab0e6451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c48af8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_spacing(text):\n",
    "    return ' '.join(wordninja.split(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e9a0169",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tweet'] = tweets_df['tweet'].apply(fix_spacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af5c6d",
   "metadata": {},
   "source": [
    "### Expanding slangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5191d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"ur\": \"your\",\n",
    "    \"bc\": \"because\",\n",
    "    \"b4\": \"before\",\n",
    "    \"idk\": \"i don't know\",\n",
    "    \"lol\": \"laughing out loud\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"pls\": \"please\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"im\": \"i am\",\n",
    "    \"dont\": \"do not\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"bt\" : \"but\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baf2168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_slang(text):\n",
    "    words = text.split()\n",
    "    expanded_words = []\n",
    "\n",
    "    for word in words:\n",
    "        if word in slang_dict:\n",
    "            expanded_words.append(slang_dict[word])\n",
    "        else:\n",
    "            expanded_words.append(word)\n",
    "    \n",
    "    return ' '.join(expanded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73bf18b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        studio life a is life requires passion dedicat...\n",
       "1        white supremacists want everyone to see the ne...\n",
       "2        safe ways to heal your acne alt ways to heal h...\n",
       "3        is the hp and the cursed child book up for res...\n",
       "4        3 rd bih day to my amazing hilarious nephew el...\n",
       "                               ...                        \n",
       "17192    thought factory left right polarisation trump ...\n",
       "17193    feeling like a mermaid hair flip never ready f...\n",
       "17194    hillary campaigned today in ohio oh my god amp...\n",
       "17195    happy at work conference right mindset leads t...\n",
       "17196    my song so glad free download shoe gaze new mu...\n",
       "Name: tweet, Length: 17197, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['tweet'].apply(expand_slang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b956b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "tweets_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a9299e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1426"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Check for duplicate values\n",
    "tweets_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d642a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = tweets_df.drop_duplicates( keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5128bdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14764</th>\n",
       "      <td>happy kidd ooo w aaa treats minion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>love my little princess loads love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10573</th>\n",
       "      <td>did anyone else think the girls choreography a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>personalised d gbp 2500 get here shop cool hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>my live cam is back on at come visit me sexy n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet\n",
       "14764                 happy kidd ooo w aaa treats minion\n",
       "4869                  love my little princess loads love\n",
       "10573  did anyone else think the girls choreography a...\n",
       "6036   personalised d gbp 2500 get here shop cool hom...\n",
       "14032  my live cam is back on at come visit me sexy n..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30192ef",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4fe90e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pralo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ddcda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb35f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_text(text):\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = nltk.word_tokenize(text)  # Tokenization\n",
    "\n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)  # Remove special characters\n",
    "\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)  # Remove stopwords\n",
    "\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))  # Stemming\n",
    "\n",
    "    return y  # Return list of processed tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd3fc9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [studio, life, life, requir, passion, dedic, w...\n",
       "1        [white, supremacist, want, everyon, see, new, ...\n",
       "2        [safe, way, heal, acn, alt, way, heal, healthi...\n",
       "3        [hp, curs, child, book, reserv, alreadi, ye, h...\n",
       "4        [3, rd, bih, day, amaz, hilari, nephew, eli, a...\n",
       "                               ...                        \n",
       "17191    [2, damn, tuff, ruff, muff, techno, citi, ng, ...\n",
       "17192    [thought, factori, left, right, polaris, trump...\n",
       "17193    [feel, like, mermaid, hair, flip, never, readi...\n",
       "17194    [hillari, campaign, today, ohio, omg, amp, use...\n",
       "17196    [song, glad, free, download, shoe, gaze, new, ...\n",
       "Name: tweet, Length: 15771, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tweets_df['tweet'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6731aba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ae8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
