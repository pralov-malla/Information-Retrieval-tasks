{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe57eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56746e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/test_tweets_anuFYb8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "631e6485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 484 entries, 0 to 483\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      484 non-null    int64 \n",
      " 1   tweet   484 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8752f983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>32326</td>\n",
       "      <td>@user @user oh.my.word! i don't think she's a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>32375</td>\n",
       "      <td>i am thankful for love. #thankful #positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>32069</td>\n",
       "      <td>l o v e   #sky #photoofday #moments #cool #ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>32132</td>\n",
       "      <td>about to watch these movies alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>32199</td>\n",
       "      <td>we are nearly ready for the off!!!   #nohampto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet\n",
       "363  32326   @user @user oh.my.word! i don't think she's a...\n",
       "412  32375   i am thankful for love. #thankful #positive     \n",
       "106  32069  l o v e   #sky #photoofday #moments #cool #ins...\n",
       "169  32132                about to watch these movies alone  \n",
       "236  32199  we are nearly ready for the off!!!   #nohampto..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e476eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = df[['tweet']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf879d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  #studiolife #aislife #requires #passion #dedic...\n",
       "1   @user #white #supremacists want everyone to s...\n",
       "2  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  is the hp and the cursed child book up for res...\n",
       "4    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6ceb714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)         # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)            # Remove @mentions\n",
    "    text = re.sub(r'#', '', text)               # Remove hashtag symbol\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)         # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()    # Normalize whitespace\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "441f4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tweet'] = tweets_df['tweet'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8548789e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'studiolife aislife requires passion dedication willpower to find newmaterialsâ'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the tweet at position 0 (first row) as an example\n",
    "tweets_df['tweet'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7191d",
   "metadata": {},
   "source": [
    "### Normalize Unicode (fix weird characters like ð, â)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e3e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_unicode(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e13f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tweet'] = tweets_df['tweet'].apply(normalize_unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e3a625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>you are sleeping and i crying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>think happy stay happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>morning sunshine  smile sexy bigboobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>something inside me dies a eyes ness smokeyeye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>life right now is amazing successful positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>few things worse than putting words into the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>model i love u take with u all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>the last formteachers lesson byebye8year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>character customization confirmed pokemonsunmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>it could be worse embarrassed unfounate trauma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet\n",
       "322                      you are sleeping and i crying\n",
       "383                             think happy stay happy\n",
       "47               morning sunshine  smile sexy bigboobs\n",
       "6    something inside me dies a eyes ness smokeyeye...\n",
       "91       life right now is amazing successful positive\n",
       "458  few things worse than putting words into the m...\n",
       "411    model i love u take with u all the time in ur  \n",
       "368           the last formteachers lesson byebye8year\n",
       "303  character customization confirmed pokemonsunmo...\n",
       "261  it could be worse embarrassed unfounate trauma..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31085a41",
   "metadata": {},
   "source": [
    "### Correcting space problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab0e6451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c48af8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_spacing(text):\n",
    "    return ' '.join(wordninja.split(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e9a0169",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tweet'] = tweets_df['tweet'].apply(fix_spacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af5c6d",
   "metadata": {},
   "source": [
    "### Expanding slangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5191d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"ur\": \"your\",\n",
    "    \"bc\": \"because\",\n",
    "    \"b4\": \"before\",\n",
    "    \"idk\": \"i don't know\",\n",
    "    \"lol\": \"laughing out loud\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"pls\": \"please\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"im\": \"i am\",\n",
    "    \"dont\": \"do not\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"bt\": \"but\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"ikr\": \"i know right\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"omw\": \"on my way\",\n",
    "    \"afaik\": \"as far as i know\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"bff\": \"best friends forever\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"ftw\": \"for the win\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"dm\": \"direct message\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"nsfw\": \"not safe for work\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"rn\": \"right now\",\n",
    "    \"tho\": \"though\",\n",
    "    \"ya\": \"yeah\",\n",
    "    \"yolo\": \"you only live once\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baf2168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_slang(text):\n",
    "    words = text.split()\n",
    "    expanded_words = []\n",
    "\n",
    "    for word in words:\n",
    "        if word in slang_dict:\n",
    "            expanded_words.append(slang_dict[word])\n",
    "        else:\n",
    "            expanded_words.append(word)\n",
    "    \n",
    "    return ' '.join(expanded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73bf18b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      studio life a is life requires passion dedicat...\n",
       "1      white supremacists want everyone to see the ne...\n",
       "2      safe ways to heal your acne alt ways to heal h...\n",
       "3      is the hp and the cursed child book up for res...\n",
       "4      3 rd bih day to my amazing hilarious nephew el...\n",
       "                             ...                        \n",
       "479      it is amazing what a day has surprises movement\n",
       "480    caffeine fix a quick cup of coffee positiv it ...\n",
       "481          green james mca voy atonement mca voy f lim\n",
       "482    pass last exam made new lashes thanks to studi...\n",
       "483                                   easter my new hero\n",
       "Name: tweet, Length: 484, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['tweet'].apply(expand_slang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b956b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "tweets_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a9299e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Check for duplicate values\n",
    "tweets_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d642a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = tweets_df.drop_duplicates( keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5128bdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>oh there is tons of stuff its like they wont d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>its so dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tried that but nothing will try again know you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>phil spencer criticizes sony of course what el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>lip o light helped shape her and it can help s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet\n",
       "137  oh there is tons of stuff its like they wont d...\n",
       "335                                        its so dark\n",
       "29   tried that but nothing will try again know you...\n",
       "161  phil spencer criticizes sony of course what el...\n",
       "70   lip o light helped shape her and it can help s..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30192ef",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4fe90e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pralo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Pralo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ddcda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For stemming\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb35f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    tokens = nltk.word_tokenize(text)  # Tokenization\n",
    "\n",
    "    y = []\n",
    "    for word in tokens:\n",
    "        if word.isalnum():  # Keep only alphanumeric tokens\n",
    "            y.append(word)\n",
    "\n",
    "    filtered = []\n",
    "    for word in y:\n",
    "        if word not in stopwords.words('english') and word not in string.punctuation:\n",
    "            filtered.append(word)\n",
    "\n",
    "    processed = []\n",
    "    for word in filtered:\n",
    "        lemma = lemmatizer.lemmatize(word)     # Lemmatization\n",
    "        stemmed = ps.stem(lemma)               # Stemming\n",
    "        processed.append(stemmed)\n",
    "\n",
    "    return processed  # Return final list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd3fc9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweets_df['tweet'] = tweets_df['tweet'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6731aba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>[day, best]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>[easter, meanwhil, white, hous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>[4, u, non, hockey, peopl, hockey, babe, ruth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>[monday, insta, gram, insta, grammer, motor, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>[rest, peac, christina, rip, rip, christina, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>[draft, 1, b, 4, pick, uni, liverpool, recognit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>[sterl, attack, bull, chase, leav, lot, despit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>[chatter, girl, guid, cho, cie, alicia, marco,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>[happi, father, day, father, father, day, sund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[white, supremacist, want, everyon, see, new, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet\n",
       "158                                        [day, best]\n",
       "422                    [easter, meanwhil, white, hous]\n",
       "145  [4, u, non, hockey, peopl, hockey, babe, ruth,...\n",
       "211  [monday, insta, gram, insta, grammer, motor, p...\n",
       "256  [rest, peac, christina, rip, rip, christina, c...\n",
       "200   [draft, 1, b, 4, pick, uni, liverpool, recognit]\n",
       "174  [sterl, attack, bull, chase, leav, lot, despit...\n",
       "441  [chatter, girl, guid, cho, cie, alicia, marco,...\n",
       "263  [happi, father, day, father, father, day, sund...\n",
       "1    [white, supremacist, want, everyon, see, new, ..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "105ae8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\pralo\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\pralo\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\pralo\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\pralo\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\pralo\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pralo\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\pralo\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install textblob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2259367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_tokens_textblob(token_list):\n",
    "    sentence = ' '.join(token_list)\n",
    "    corrected = str(TextBlob(sentence).correct())\n",
    "    return corrected.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "876a2d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['tweet'] = tweets_df['tweet'].apply(correct_tokens_textblob)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4241095a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>[character, custom, confirm, poleon, sun, moon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>[london, self, in, smile, love, photo, day, pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>[photo, last, year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>[shock, amp, hear, christian, grim, in, past, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>[may, day, surprise, movement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>[great, screw, job, 2016, catch, break, impact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>[weekend, she, may, time, friend, family, summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>[caffein, fix, quick, cup, coffee, positive, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>[think, go, best, match, give, ever, watch, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>[never, previous, secret, screen, star, move, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet\n",
       "303  [character, custom, confirm, poleon, sun, moon...\n",
       "206  [london, self, in, smile, love, photo, day, pi...\n",
       "452                                [photo, last, year]\n",
       "341  [shock, amp, hear, christian, grim, in, past, ...\n",
       "479                     [may, day, surprise, movement]\n",
       "366  [great, screw, job, 2016, catch, break, impact...\n",
       "424  [weekend, she, may, time, friend, family, summ...\n",
       "480  [caffein, fix, quick, cup, coffee, positive, a...\n",
       "209  [think, go, best, match, give, ever, watch, we...\n",
       "349  [never, previous, secret, screen, star, move, ..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39241abc",
   "metadata": {},
   "source": [
    "### Text is good enough for further tasks like (Indexing, Emebedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cabbebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv(\"../data/tweets.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
